Polynomial Regression, Multi Regression


■ 내가 추가한 파생변수가 유의미한 파생변수인지 확인을 하고 여러 독립변수들 
    중에 불필요한 독립변수를 제거하고 필요한 독립변수들만 골라내서 회귀분석 
    할 때 사용하는 step 함수를 파이썬으로 구현하기

# 1. R 의 step 함수의 기능을 가지고 있는 패키지 등 import 합니다.
from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression
import pandas as pd

# 2. 데이터 불러오기
df = pd.read_csv("c:\\data\\insurance.csv", engine='python', encoding='CP949') 
print(df)

# 3. 컬럼을 인코딩합니다.
df = pd.get_dummies(df, drop_first=True)
print(df.head())   # 총 9개의 컬럼이 만들어졌음

print(df.columns.values)  # 컬럼명을 numpy array 형태로 출력
print(df.iloc[ : ,3])  # expenses

# 4. 독립변수와 종속변수를 numpy array 로 변환합니다.
#X = # 독립변수들 (numpy array 형태) --> age+sex+bim+children+smoker+region
X = df.iloc[ : ,[0,1,2,4,5,6,7,8]].to_numpy()
#y = # 종속변수 --> expenses
y = df.iloc[ : ,3].to_numpy()

# 5. 회귀 모델을 생성합니다.
model = LinearRegression()

# 6.  step 함수를 이용해서 필요한 독립변수들을 선별합니다.
#selector = RFE(회귀모델명, n_features_to_select=선별할 독립변수의 개수, step=스텝회수)
selector = RFE(model, n_features_to_select=6, step=1)

selector = selector.fit(X, y)

print(selector.support_)  # [False  True  True False  True  True  True  True]
                          # 8개의 독립변수들 중에 선택된 6개가 True 로 출력이 됨

print(selector.ranking_)  # [2 1 1 3 1 1 1 1]
                          # 8개의 독립변수들의 중요도 순위가 출력이 됨

age' 'bmi' 'children' 'sex_male' 'smoker_yes' 'region_northwest' 'region_southeast' 'region_southwest'] 의 8개의 독립변수들 중
bmi, children, smoker_yes, region_northwest, region_southeast, region_southwest 6개 변수 선택


문제26. 위의 코드를 다시 테스트 하는데 지금 추가한 파생변수가 필요한 파생변수인지 
	   확인하는 작업을 수행하시오 ! bmi30이 중요한 파생변수인지 확인하시오 !

def func_1(x):
    if x >= 30:
        return 1
    else:
        return 0

df['bmi30'] = df['bmi'].apply(func_1)
print(df)


답:
# 1. R 의 step 함수의 기능을 가지고 있는 패키지 등 import 합니다.
from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression
import pandas as pd

# 2. 데이터 불러오기
df = pd.read_csv("c:\\data\\insurance.csv", engine='python', encoding='CP949') 

# 3. 파생변수 추가
def func_1(x):
    if x >= 30:
        return 1
    else:
        return 0

df['bmi30'] = df['bmi'].apply(func_1)
print(df.head())

# 4. 컬럼을 인코딩합니다.
df = pd.get_dummies(df, drop_first=True)
print(df.head())   # 총 10개의 컬럼이 만들어졌음
print(df.columns.values)  # 컬럼명을 numpy array 형태로 출력


# 5. 독립변수와 종속변수를 numpy array 로 변환합니다.
#X = # 독립변수들 (numpy array 형태) --> age+sex+bim+children+smoker+region
X = df.iloc[ : ,[0,1,2,4,5,6,7,8,9]].to_numpy()
#y = # 종속변수 --> expenses
y = df.iloc[ : ,3].to_numpy()

# 6. 회귀 모델을 생성합니다.
model = LinearRegression()

# 7.  step 함수를 이용해서 필요한 독립변수들을 선별합니다.
#selector = RFE(회귀모델명, n_features_to_select=선별할 독립변수의 개수, step=스텝회수)
selector = RFE(model, n_features_to_select=6, step=1)

selector = selector.fit(X, y) 

print(selector.support_)  # [False False  True  True False  True  True  True  True]
                          # 9개의 독립변수들 중에 선택된 6개가 True 로 출력이 됨

print(selector.ranking_)  # [2 4 1 1 3 1 1 1 1]
                          # 9개의 독립변수들의 중요도 순위가 출력이 됨

['age' 'bmi' 'children' 'bmi30' 'sex_male' 'smoker_yes'
 'region_northwest' 'region_southeast' 'region_southwest'] 의 9개의 독립변수 중에
children, bmi30, smoker_yes, region_northwest, region_southeast, region_southwest
독립변수 6개 선택

bmi30은 중요한 파생변수로 선택됨.


문제27. 비만이면서 흡연을 하는 사람에 대한 파생변수를 bmi30_smoker 라는 
	   이름으로 추가하시오 !

# 1. R 의 step 함수의 기능을 가지고 있는 패키지 등 import 합니다.
from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression
import pandas as pd

# 2. 데이터 불러오기
df = pd.read_csv("c:\\data\\insurance.csv", engine='python', encoding='CP949') 

# 3. 파생변수 추가
def func_1(x):
    if x >= 30:
        return 1
    else:
        return 0

df['bmi30'] = df['bmi'].apply(func_1)
print(df.head())

# 4. 컬럼을 인코딩합니다.
df = pd.get_dummies(df, drop_first=True)
print(df.head())   # 총 10개의 컬럼이 만들어졌음
print(df.columns.values)  # 컬럼명을 numpy array 형태로 출력

df['bmi30_smoker'] = df['bmi30']*df['smoker_yes'] 

# 5. 독립변수와 종속변수를 numpy array 로 변환합니다.
#X = # 독립변수들 (numpy array 형태) 
X = df.iloc[ : ,[0,1,2,4,5,6,7,8,9,10]].to_numpy()
#y = # 종속변수 --> expenses
y = df.iloc[ : ,3].to_numpy()

# 6. 회귀 모델을 생성합니다.
model = LinearRegression()

# 7.  RFE(후진제거법) 함수를 이용해서 필요한 독립변수들을 선별합니다.
#selector = RFE(회귀모델명, n_features_to_select=선별할 독립변수의 개수, step=한번에 제거할 개수)
selector = RFE(model, n_features_to_select=6, step=1)

selector = selector.fit(X, y) 

print(selector.support_)  # [False False  True False  True  True False  True  True  True]
                          # 10개의 독립변수들 중에 선택된 6개가 True 로 출력이 됨

print(selector.ranking_)  # [3 5 1 4 1 1 2 1 1 1]
                          # 10개의 독립변수들의 중요도 순위가 출력이 됨

변수선택:
['children'   'sex_male' 'smoker_yes' 'region_southeast' 'region_southwest' 'bmi30_smoker']


-------------------------------------------------------------------------------------------------------
# 학습을 마친 모형에 test data를 적용하여 결정계수(R-제곱) 계산
model.fit(X, y)
r_square = model.score(X, y)

print(r_square)
print('\n')

# 회귀식의 기울기
print('기울기 a: ', model.coef_)
print('\n')

# 회귀식의 y절편
print('y절편 b', model.intercept_)
print('\n')

결과:
0.8638704460994961

기울기 a:  [  263.24284784   114.82824556   520.4738381   -863.25462888
  -491.12953961 13402.28725234  -266.79968469  -824.57297575
 -1223.8696938  19794.26437576]

y절편 b -4740.682154731916

-------------------------------------------------전체 독립변수 회귀 결과
model = smf.ols('expenses ~ age+bmi+children+bmi30+sex_male+smoker_yes+region_northwest+region_southeast+region_southwest+bmi30_smoker', data=df)
result = model.fit()
print( result.summary() ) 


OLS Regression Results                            
==============================================================================
Dep. Variable:               expenses   R-squared:                       0.864
Model:                            OLS   Adj. R-squared:                  0.863
Method:                 Least Squares   F-statistic:                     842.1
Date:                Wed, 24 Feb 2021   Prob (F-statistic):               0.00
Time:                        17:11:25   Log-Likelihood:                -13144.
No. Observations:                1338   AIC:                         2.631e+04
Df Residuals:                    1327   BIC:                         2.637e+04
Df Model:                          10                                         
Covariance Type:            nonrobust                                         
====================================================================================
                       coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept        -4740.6822    960.019     -4.938      0.000   -6624.002   -2857.362
age                263.2428      8.805     29.896      0.000     245.969     280.517
bmi                114.8282     34.574      3.321      0.001      47.003     182.653
children           520.4738    101.959      5.105      0.000     320.455     720.493
bmi30             -863.2546    425.900     -2.027      0.043   -1698.765     -27.744
sex_male          -491.1295    246.568     -1.992      0.047    -974.834      -7.425
smoker_yes         1.34e+04    443.918     30.191      0.000    1.25e+04    1.43e+04
region_northwest  -266.7997    352.417     -0.757      0.449    -958.154     424.555
region_southeast  -824.5730    354.812     -2.324      0.020   -1520.627    -128.519
region_southwest -1223.8697    353.685     -3.460      0.001   -1917.713    -530.026
bmi30_smoker      1.979e+04    610.110     32.444      0.000    1.86e+04     2.1e+04
==============================================================================
Omnibus:                      871.061   Durbin-Watson:                   2.060
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7318.497
Skew:                           3.087   Prob(JB):                         0.00
Kurtosis:                      12.652   Cond. No.                         420.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

----------------------------------------------------
-----------------------------------------------------------------------------------------
# 선택된 변수로 구한 결과
r_square = selector.score(X, y)

print(r_square)
print('\n')

# 회귀식의 기울기
print('기울기 a: ', model.coef_)
print('\n')

# 회귀식의 y절편
print('y절편 b', model.intercept_)
print('\n')

0.7676628662247236


기울기 a:  [  263.24284784   114.82824556   520.4738381   -863.25462888
  -491.12953961 13402.28725234  -266.79968469  -824.57297575
 -1223.8696938  19794.26437576]


y절편 b -4740.682154731916

-----------------------------------------------------------------------------------------

문제28. (오늘의 마지막 문제) 문제 27번에서 선별된 독립변수들만 가지고 회귀모델을 생성하고
	   훈련시켜 나온 결정계수가 어떻게 되는지 확인하시오 !

힌트:
X = ?
y = ? 
model.fit(X, y)
r_square = model.score(X, y)

print(r_square)


#
import statsmodels.formula.api as smf

model = smf.ols('expenses ~ children + sex_male + smoker_yes + region_southeast + region_southwest + bmi30_smoker', data=df)
result = model.fit()
print( result.summary() )  # 결정계수 : 0.768


                            OLS Regression Results                            
==============================================================================
Dep. Variable:               expenses   R-squared:                       0.768
Model:                            OLS   Adj. R-squared:                  0.767
Method:                 Least Squares   F-statistic:                     733.0
Date:                Wed, 24 Feb 2021   Prob (F-statistic):               0.00
Time:                        17:06:41   Log-Likelihood:                -13501.
No. Observations:                1338   AIC:                         2.702e+04
Df Residuals:                    1331   BIC:                         2.705e+04
Df Model:                           6                                         
Covariance Type:            nonrobust                                         
====================================================================================
                       coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------------
Intercept         8396.1342    321.308     26.131      0.000    7765.810    9026.459
children           655.5237    132.802      4.936      0.000     394.999     916.048
sex_male          -631.9316    321.440     -1.966      0.050   -1262.515      -1.348
smoker_yes        1.285e+04    546.291     23.517      0.000    1.18e+04    1.39e+04
region_southeast  -487.8482    385.419     -1.266      0.206   -1243.942     268.246
region_southwest  -973.5635    398.420     -2.444      0.015   -1755.164    -191.963
bmi30_smoker      2.043e+04    712.593     28.672      0.000     1.9e+04    2.18e+04
==============================================================================
Omnibus:                      378.619   Durbin-Watson:                   2.061
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              978.911
Skew:                           1.491   Prob(JB):                    2.71e-213
Kurtosis:                       5.943   Cond. No.                         9.77
===============================================================
