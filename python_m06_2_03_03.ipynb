{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "python_m06_2_03_03.ipynb",
      "provenance": [],
      "mount_file_id": "17BX21EA67fnaFDCS7mkc39q95ekGCgyu",
      "authorship_tag": "ABX9TyPnMgatRq1YVa83s6etwQq4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yhy0519/Machine_learning_of_Python/blob/main/python_m06_2_03_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3LuODOG5W40"
      },
      "source": [
        "# **■ 랜덤 포레스트(Random Forest)**\r\n",
        "\r\n",
        "랜덤포레스트는 의사결정나무의 특징인 분산이 크다는 점을 고려하여 \r\n",
        "배깅과 부스팅보다 더 많은 무작위성을 주어 약한 학습기들을 생성한 후  \r\n",
        "이를 선형결합하여 최종 학습기를 만드는 방법입니다.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiyF614Q5mwT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjWJhPKw5nHd"
      },
      "source": [
        "**예제1. iris 데이터를 의사결정트리로 분류하는 실습**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ9PlLP4rRt7"
      },
      "source": [
        "## 1. 필요한 패키지를 로드합니다.\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.model_selection import train_test_split \r\n",
        "import pandas as pd  # 데이터 전처리를 위해서 "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-wDOnys6Brk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFOyGfTE5sBm"
      },
      "source": [
        "## 2. iris2.csv 불러와서 독립변수들과 종숙변수를 생성합니다.\r\n",
        "col_names = ['sepal-length', 'sepal-width','petal-length', 'petal-width','Class']\r\n",
        "\r\n",
        "df =  pd.read_csv('/content/drive/MyDrive/data/iris2.csv', encoding='UTF-8', header=None, names=col_names)\r\n",
        "\r\n",
        "X = df.iloc[:,:-1].to_numpy() \r\n",
        "y = df.iloc[:,-1].to_numpy()   "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39KK-pTy6CKk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhVimTOo5uRd",
        "outputId": "7af90d3e-a11d-49a1-af0b-6285be195f75"
      },
      "source": [
        "## 3. 훈련 데이터와 테스트 데이터를 8:2 로 분리합니다.\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \r\n",
        "                                                    test_size=0.2, random_state=121)\r\n",
        "print(X_train.shape) \r\n",
        "print(X_test.shape)  \r\n",
        "print('\\n')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120, 4)\n",
            "(30, 4)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11KdnxtF6DKc"
      },
      "source": [
        "## 4. 의사결정트리 모델을 생성합니다.\r\n",
        "dtree = DecisionTreeClassifier()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWiyK0376bNT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "Ijqjo2Qb6GkU",
        "outputId": "33cd4255-0d62-482c-8617-1334c2f492db"
      },
      "source": [
        "## 5. 의사결정트리의 gridsearch 모델을 생성합니다.\r\n",
        "### parameter 들을 dictionary 형태로 설정\r\n",
        "parameters = {'max_depth':[1,2,3,4], 'min_samples_split':[2,3,4]}\r\n",
        "\r\n",
        "# param_grid의 하이퍼 파라미터들을 3개의 train, test set fold 로 나누어서 테스트 수행 설정.  \r\n",
        "### refit=True 가 default 임. True이면 가장 좋은 파라미터 설정으로 재 학습 시킴.  \r\n",
        "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\r\n",
        "\r\n",
        "# 붓꽃 Train 데이터로 param_grid의 하이퍼 파라미터들을 순차적으로 학습/평가 .\r\n",
        "grid_dtree.fit(X_train, y_train)\r\n",
        "\r\n",
        "# GridSearchCV 결과 추출하여 DataFrame으로 변환\r\n",
        "scores_df = pd.DataFrame(grid_dtree.cv_results_)\r\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score', \\\r\n",
        "           'split0_test_score', 'split1_test_score', 'split2_test_score']]\r\n",
        " \r\n",
        "scores_df"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>param_min_samples_split</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000889</td>\n",
              "      <td>0.000202</td>\n",
              "      <td>0.000589</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>1.110223e-16</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000894</td>\n",
              "      <td>0.000309</td>\n",
              "      <td>0.000560</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>1.110223e-16</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000823</td>\n",
              "      <td>0.000220</td>\n",
              "      <td>0.000495</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 4}</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>1.110223e-16</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000836</td>\n",
              "      <td>0.000212</td>\n",
              "      <td>0.000524</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.950</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3.118048e-02</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000835</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.000596</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.950</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3.118048e-02</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000794</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>0.000512</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 4}</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.950</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3.118048e-02</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000417</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.000277</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.950</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>2.041241e-02</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000421</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000258</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.950</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>2.041241e-02</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.000416</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000284</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 4}</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.950</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>2.041241e-02</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000426</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>{'max_depth': 4, 'min_samples_split': 2}</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>3.118048e-02</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.000417</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.000274</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>{'max_depth': 4, 'min_samples_split': 3}</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>3.535534e-02</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.000404</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000260</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>{'max_depth': 4, 'min_samples_split': 4}</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.925</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>3.118048e-02</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "0        0.000889      0.000202         0.000589        0.000102   \n",
              "1        0.000894      0.000309         0.000560        0.000082   \n",
              "2        0.000823      0.000220         0.000495        0.000024   \n",
              "3        0.000836      0.000212         0.000524        0.000044   \n",
              "4        0.000835      0.000038         0.000596        0.000018   \n",
              "5        0.000794      0.000050         0.000512        0.000051   \n",
              "6        0.000417      0.000022         0.000277        0.000004   \n",
              "7        0.000421      0.000005         0.000258        0.000001   \n",
              "8        0.000416      0.000018         0.000284        0.000007   \n",
              "9        0.000426      0.000006         0.000266        0.000002   \n",
              "10       0.000417      0.000003         0.000274        0.000013   \n",
              "11       0.000404      0.000005         0.000260        0.000006   \n",
              "\n",
              "   param_max_depth param_min_samples_split  \\\n",
              "0                1                       2   \n",
              "1                1                       3   \n",
              "2                1                       4   \n",
              "3                2                       2   \n",
              "4                2                       3   \n",
              "5                2                       4   \n",
              "6                3                       2   \n",
              "7                3                       3   \n",
              "8                3                       4   \n",
              "9                4                       2   \n",
              "10               4                       3   \n",
              "11               4                       4   \n",
              "\n",
              "                                      params  split0_test_score  \\\n",
              "0   {'max_depth': 1, 'min_samples_split': 2}              0.700   \n",
              "1   {'max_depth': 1, 'min_samples_split': 3}              0.700   \n",
              "2   {'max_depth': 1, 'min_samples_split': 4}              0.700   \n",
              "3   {'max_depth': 2, 'min_samples_split': 2}              0.925   \n",
              "4   {'max_depth': 2, 'min_samples_split': 3}              0.925   \n",
              "5   {'max_depth': 2, 'min_samples_split': 4}              0.925   \n",
              "6   {'max_depth': 3, 'min_samples_split': 2}              0.975   \n",
              "7   {'max_depth': 3, 'min_samples_split': 3}              0.975   \n",
              "8   {'max_depth': 3, 'min_samples_split': 4}              0.975   \n",
              "9   {'max_depth': 4, 'min_samples_split': 2}              0.975   \n",
              "10  {'max_depth': 4, 'min_samples_split': 3}              0.925   \n",
              "11  {'max_depth': 4, 'min_samples_split': 4}              0.975   \n",
              "\n",
              "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
              "0                 0.7              0.700         0.700000    1.110223e-16   \n",
              "1                 0.7              0.700         0.700000    1.110223e-16   \n",
              "2                 0.7              0.700         0.700000    1.110223e-16   \n",
              "3                 1.0              0.950         0.958333    3.118048e-02   \n",
              "4                 1.0              0.950         0.958333    3.118048e-02   \n",
              "5                 1.0              0.950         0.958333    3.118048e-02   \n",
              "6                 1.0              0.950         0.975000    2.041241e-02   \n",
              "7                 1.0              0.950         0.975000    2.041241e-02   \n",
              "8                 1.0              0.950         0.975000    2.041241e-02   \n",
              "9                 1.0              0.925         0.966667    3.118048e-02   \n",
              "10                1.0              0.925         0.950000    3.535534e-02   \n",
              "11                1.0              0.925         0.966667    3.118048e-02   \n",
              "\n",
              "    rank_test_score  \n",
              "0                10  \n",
              "1                10  \n",
              "2                10  \n",
              "3                 6  \n",
              "4                 6  \n",
              "5                 6  \n",
              "6                 1  \n",
              "7                 1  \n",
              "8                 1  \n",
              "9                 4  \n",
              "10                9  \n",
              "11                4  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ti3mLG6_6ebV",
        "outputId": "760c0062-e533-40cd-eced-f4381c2c3b0b"
      },
      "source": [
        "# rank_test_score 가 1인 것들이 가장 좋은 하이퍼 파라미터 조합\r\n",
        "\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\r\n",
        "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dtree.best_score_))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}\n",
            "GridSearchCV 최고 정확도: 0.9750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUsoEv346kSU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsrySSW96ibl",
        "outputId": "d33201eb-339b-4bf6-83c4-3917f40cf009"
      },
      "source": [
        "# GridSearchCV의 refit으로 이미 학습이 된 estimator 반환\r\n",
        "estimator = grid_dtree.best_estimator_\r\n",
        "\r\n",
        "# GridSearchCV의 best_estimator_는 이미 최적 하이퍼 파라미터로 학습이 됨\r\n",
        "pred = estimator.predict(X_test)\r\n",
        "print('테스트 데이터 세트 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "테스트 데이터 세트 정확도: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Houf3FzC7D6-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-zYIFh57D37"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sB4fkWx7D0g"
      },
      "source": [
        "**예제2. iris 데이터를 랜덤포레스트로 분류하는 실습**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBcIlgbb7Ge8"
      },
      "source": [
        "## 1. 필요한 패키지를 로드합니다.\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.model_selection import train_test_split \r\n",
        "import pandas as pd  # 데이터 전처리를 위해서 \r\n",
        "from  sklearn.ensemble   import  RandomForestClassifier "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhCtKlBF7MAv"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jb3_iGM7LAR"
      },
      "source": [
        "## 2. 독립변수들과 종속변수를 생성합니다.\r\n",
        "col_names = ['sepal-length', 'sepal-width','petal-length', 'petal-width','Class']\r\n",
        "\r\n",
        "df =  pd.read_csv('/content/drive/MyDrive/data/iris2.csv', encoding='UTF-8', header=None, names=col_names)\r\n",
        "\r\n",
        "X = df.iloc[:,:-1].to_numpy() \r\n",
        "y = df.iloc[:,-1].to_numpy()   "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FQfhjA17Nun"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFpEok__7M8Z"
      },
      "source": [
        "## 3. 훈련 데이터와 테스트 데이터를 8:2로 나눕니다.\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \r\n",
        "                                                    test_size=0.2, random_state=121)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP7w77FO7QIx"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "VPftPpBq7OxA",
        "outputId": "3d9cb19e-d9d8-448e-8d66-d0454135fd82"
      },
      "source": [
        "## 4. 랜덤포레스트 모델을 생성합니다.\r\n",
        "rftree = RandomForestClassifier()\r\n",
        "\r\n",
        "### parameter 들을 dictionary 형태로 설정\r\n",
        "\r\n",
        "parameters = {\r\n",
        "    'bootstrap': [True],   # 데이터를 샘플링해서 가져올지 전체를 다 가져올지를 결정\r\n",
        "\t\t\t                     # 이상치가 있을때는 bootstrop 설정해야 좋음\r\n",
        "    'max_depth': [80, 90, 100],  # 나무의 깊이\r\n",
        "    'max_features': [2, 3],     # 가장 성능이 좋은 트리의 최종 개수\r\n",
        "    'min_samples_leaf': [3, 4, 5],   # 가지의 리프의 최소 개수\r\n",
        "    'min_samples_split': [8, 10, 12],  # 가지를 split 하는 최소 개수\r\n",
        "    'n_estimators': [100, 200, 300, 1000]  # 나무의 개수\r\n",
        "}\r\n",
        "\r\n",
        "# param_grid의 하이퍼 파라미터들을 3개의 train, test set fold 로 나누어서 테스트 수행 설정.  \r\n",
        "### refit=True 가 default 임. True이면 가장 좋은 파라미터 설정으로 재 학습 시킴.  \r\n",
        "grid_dtree = GridSearchCV(rftree, param_grid=parameters, cv=3, refit=True,  n_jobs = -1, verbose = 2 )\r\n",
        "\r\n",
        "# 붓꽃 Train 데이터로 param_grid의 하이퍼 파라미터들을 순차적으로 학습/평가 .\r\n",
        "grid_dtree.fit(X_train, y_train)\r\n",
        "\r\n",
        "# GridSearchCV 결과 추출하여 DataFrame으로 변환\r\n",
        "scores_df = pd.DataFrame(grid_dtree.cv_results_)\r\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score', \\\r\n",
        "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   17.5s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=-1)]: Done 648 out of 648 | elapsed:  5.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'bootstrap': True, 'max_depth': 80, 'max_feat...</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>149</td>\n",
              "      <td>0.900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'bootstrap': True, 'max_depth': 80, 'max_feat...</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>9</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'bootstrap': True, 'max_depth': 80, 'max_feat...</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>149</td>\n",
              "      <td>0.900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'bootstrap': True, 'max_depth': 80, 'max_feat...</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>149</td>\n",
              "      <td>0.900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'bootstrap': True, 'max_depth': 80, 'max_feat...</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>149</td>\n",
              "      <td>0.900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>{'bootstrap': True, 'max_depth': 100, 'max_fea...</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>9</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>{'bootstrap': True, 'max_depth': 100, 'max_fea...</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>9</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>{'bootstrap': True, 'max_depth': 100, 'max_fea...</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>9</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>{'bootstrap': True, 'max_depth': 100, 'max_fea...</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>9</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>{'bootstrap': True, 'max_depth': 100, 'max_fea...</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>9</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>216 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                params  mean_test_score  \\\n",
              "0    {'bootstrap': True, 'max_depth': 80, 'max_feat...         0.950000   \n",
              "1    {'bootstrap': True, 'max_depth': 80, 'max_feat...         0.958333   \n",
              "2    {'bootstrap': True, 'max_depth': 80, 'max_feat...         0.950000   \n",
              "3    {'bootstrap': True, 'max_depth': 80, 'max_feat...         0.950000   \n",
              "4    {'bootstrap': True, 'max_depth': 80, 'max_feat...         0.950000   \n",
              "..                                                 ...              ...   \n",
              "211  {'bootstrap': True, 'max_depth': 100, 'max_fea...         0.958333   \n",
              "212  {'bootstrap': True, 'max_depth': 100, 'max_fea...         0.958333   \n",
              "213  {'bootstrap': True, 'max_depth': 100, 'max_fea...         0.958333   \n",
              "214  {'bootstrap': True, 'max_depth': 100, 'max_fea...         0.958333   \n",
              "215  {'bootstrap': True, 'max_depth': 100, 'max_fea...         0.958333   \n",
              "\n",
              "     rank_test_score  split0_test_score  split1_test_score  split2_test_score  \n",
              "0                149              0.900                1.0               0.95  \n",
              "1                  9              0.925                1.0               0.95  \n",
              "2                149              0.900                1.0               0.95  \n",
              "3                149              0.900                1.0               0.95  \n",
              "4                149              0.900                1.0               0.95  \n",
              "..               ...                ...                ...                ...  \n",
              "211                9              0.925                1.0               0.95  \n",
              "212                9              0.925                1.0               0.95  \n",
              "213                9              0.925                1.0               0.95  \n",
              "214                9              0.925                1.0               0.95  \n",
              "215                9              0.925                1.0               0.95  \n",
              "\n",
              "[216 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGhygHH685z0",
        "outputId": "beec1d05-5f66-43de-a64d-d50e183b967b"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\r\n",
        "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dtree.best_score_))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV 최적 파라미터: {'bootstrap': True, 'max_depth': 80, 'max_features': 2, 'min_samples_leaf': 4, 'min_samples_split': 12, 'n_estimators': 200}\n",
            "GridSearchCV 최고 정확도: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aspRvCZKAbbT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiU_QIvL7Sur",
        "outputId": "23eac95a-05f5-4e7a-b734-5aadc150eca4"
      },
      "source": [
        "# GridSearchCV의 refit으로 이미 학습이 된 estimator 반환\r\n",
        "estimator = grid_dtree.best_estimator_\r\n",
        "\r\n",
        "# GridSearchCV의 best_estimator_는 이미 최적 하이퍼 파라미터로 학습이 됨\r\n",
        "pred = estimator.predict(X_test)\r\n",
        "print('테스트 데이터 세트 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "테스트 데이터 세트 정확도: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv3ZNbAW7njW"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g-niqL27nfG"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kFFKwA17nYk"
      },
      "source": [
        "**예제3. 시본의 타이타닉 데이터로 랜덤포레스트 모델 생성하기**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJv20gd37oJT"
      },
      "source": [
        "from sklearn import metrics\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# 1단계 csv ---> 데이터 프레임으로 변환\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "df = sns.load_dataset('titanic')\r\n",
        "\r\n",
        "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\r\n",
        "pd.set_option('display.max_columns',15)\r\n",
        "\r\n",
        "# 파생변수를 생성한다.\r\n",
        "mask4 = (df.age<10) | (df.sex=='female') \r\n",
        "df['child_women']=mask4.astype(int)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CysrvMz_7uV5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQQ-BiHw7tKq",
        "outputId": "85c21ba0-233a-49fb-ee38-12b631488d32"
      },
      "source": [
        "# 2단계 결측치 확인하고 제거하거나 치환한다.\r\n",
        "# 2.1 타이타닉 데이터 프레임의 자료형을 확인한다.\r\n",
        "df.info()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 16 columns):\n",
            " #   Column       Non-Null Count  Dtype   \n",
            "---  ------       --------------  -----   \n",
            " 0   survived     891 non-null    int64   \n",
            " 1   pclass       891 non-null    int64   \n",
            " 2   sex          891 non-null    object  \n",
            " 3   age          714 non-null    float64 \n",
            " 4   sibsp        891 non-null    int64   \n",
            " 5   parch        891 non-null    int64   \n",
            " 6   fare         891 non-null    float64 \n",
            " 7   embarked     889 non-null    object  \n",
            " 8   class        891 non-null    category\n",
            " 9   who          891 non-null    object  \n",
            " 10  adult_male   891 non-null    bool    \n",
            " 11  deck         203 non-null    category\n",
            " 12  embark_town  889 non-null    object  \n",
            " 13  alive        891 non-null    object  \n",
            " 14  alone        891 non-null    bool    \n",
            " 15  child_women  891 non-null    int64   \n",
            "dtypes: bool(2), category(2), float64(2), int64(5), object(5)\n",
            "memory usage: 87.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SW89cax7zu0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftamhAZQ7y3L"
      },
      "source": [
        "# 2.2 결측치(NaN) 을 확인한다.\r\n",
        "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\r\n",
        "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함.\r\n",
        "#        embark 와 embark_town 이 같은 데이터여서 embark 컬럼을 삭제해야함\r\n",
        "\r\n",
        "rdf = df.drop(['deck','embark_town'], axis =1)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6Y25wVM70qY"
      },
      "source": [
        "# 2.4 age(나이) 열에 나이가 없는 모든행을 삭제한다.\r\n",
        "# 데이터가 한개라도 없으면 drop 해라 (how = 'any')\r\n",
        "# 모든 데이터가 없으면 drop 해라 (how = 'all')\r\n",
        "\r\n",
        "rdf = rdf.dropna( subset=['age'], how='any', axis=0)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEhJZgEU73V8"
      },
      "source": [
        "# 2.5 embark 열의 NaN 값을 승선도시중 가장 많이 출현한 값으로 치환하기\r\n",
        "\r\n",
        "most_freq = rdf['embarked'].value_counts().idxmax()\r\n",
        "rdf['embarked'].fillna(most_freq, inplace = True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqrW-ouP76er"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "oCXn_fCK75id",
        "outputId": "958496da-9682-4768-e5cb-183e6683490a"
      },
      "source": [
        "# 3단계 범주형 데이터를 숫자형으로 변환하기\r\n",
        "# 3.1 feature selection (분석에 필요한 속성을 선택)\r\n",
        "\r\n",
        "ndf = rdf[['survived','pclass','sex','age','sibsp','parch','embarked','child_women']]\r\n",
        "ndf"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>embarked</th>\n",
              "      <th>child_women</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>Q</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Q</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>714 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     survived  pclass     sex   age  sibsp  parch embarked  child_women\n",
              "0           0       3    male  22.0      1      0        S            0\n",
              "1           1       1  female  38.0      1      0        C            1\n",
              "2           1       3  female  26.0      0      0        S            1\n",
              "3           1       1  female  35.0      1      0        S            1\n",
              "4           0       3    male  35.0      0      0        S            0\n",
              "..        ...     ...     ...   ...    ...    ...      ...          ...\n",
              "885         0       3  female  39.0      0      5        Q            1\n",
              "886         0       2    male  27.0      0      0        S            0\n",
              "887         1       1  female  19.0      0      0        S            1\n",
              "889         1       1    male  26.0      0      0        C            0\n",
              "890         0       3    male  32.0      0      0        Q            0\n",
              "\n",
              "[714 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMvMdxIH7-Uh"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx77ciJ_79h0"
      },
      "source": [
        "# 선택된 컬럼중 2개(sex, embarked) 가 범주형이다.\r\n",
        "#3.2 범주형 데이터를 숫자로 변환하기(원핫 인코딩)\r\n",
        "\r\n",
        "gender = pd.get_dummies(ndf['sex'])\r\n",
        "ndf = pd.concat([ndf,gender], axis= 1)\r\n",
        "onehot_embarked = pd.get_dummies(ndf['embarked'])\r\n",
        "ndf = pd.concat([ndf,onehot_embarked],axis=1)\r\n",
        "ndf.drop(['sex','embarked'], axis=1, inplace = True)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSpFgvnUAeKU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "089vRhyN7_-N"
      },
      "source": [
        "# 4단계 표준화\r\n",
        "# 4.1 독립변수와 종속변수(라벨) 을 지정한다.\r\n",
        "# survived  pclass   age  sibsp  parch  female  male  C  Q  S\r\n",
        "#   라벨                       데이터\r\n",
        "# 종속변수                     독립변수\r\n",
        "\r\n",
        "x = ndf[ ['pclass', 'age' ,'sibsp', 'parch' ,'female' ,'male', 'C' ,'Q' ,'S', 'child_women'] ]\r\n",
        "y = ndf['survived'] # 종속변수\r\n",
        "\r\n",
        "# 4.2 독립변수들을 표준화 한다.\r\n",
        "\r\n",
        "from sklearn import preprocessing\r\n",
        "X = preprocessing.StandardScaler().fit(x).transform(x)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcOXij0-8D9n"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lpzurock8DO8"
      },
      "source": [
        "# 5단계 훈련 데이터를 훈련 데이터 / 테스트 데이터로 나눈다 (7:3)\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,\r\n",
        "                                                 random_state = 33)\r\n",
        "\r\n",
        "# sklearn 라이브러리에서 나이브베이즈 분류 모형 가져오기\r\n",
        "\r\n",
        "from  sklearn.ensemble   import  RandomForestClassifier \r\n",
        "\r\n",
        "tree_model = RandomForestClassifier( n_estimators=100,\r\n",
        "                                     oob_score=True,\r\n",
        "                                    random_state= 9 )  "
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35A_yMTe8I43"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdKfK-Y_8F9s",
        "outputId": "c58be84e-2923-49b3-9291-187f255e8ea7"
      },
      "source": [
        "tree_model.fit( X_train, y_train )"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=True, random_state=9, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLdRaMNe8JGj"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDU_LDtk8HJw",
        "outputId": "3f3edca9-03e7-411c-dd24-6364ceb1d09c"
      },
      "source": [
        "print ( tree_model.oob_score_)    # 랜덤포레스트 모델 평가 지표"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7454909819639278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnCoHC1L8Jd9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiMn7VkY8Hwi"
      },
      "source": [
        "# 7단계 테스트 데이터로 예측을 한다.\r\n",
        "\r\n",
        "y_hat = tree_model.predict( X_test )"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0lMkvXLAgS3"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2PgScWC8L2t",
        "outputId": "96c9e33e-2a51-4c45-c6ce-3fc84678dab9"
      },
      "source": [
        "# 8단계 모형의 예측능력을 평가한다.\r\n",
        "\r\n",
        "from sklearn import metrics\r\n",
        "\r\n",
        "randomforest_matrix = metrics.confusion_matrix( y_test, y_hat )\r\n",
        "\r\n",
        "print( randomforest_matrix )"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[102  24]\n",
            " [ 18  71]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T202yhkS8NVm",
        "outputId": "f248e457-3843-440b-e3c0-682dba492c87"
      },
      "source": [
        "tn, fp, fn, tp = metrics.confusion_matrix( y_test, y_hat ).ravel()\r\n",
        "\r\n",
        "f1_report = metrics.classification_report( y_test, y_hat )\r\n",
        "\r\n",
        "print( f1_report )\r\n",
        "\r\n",
        "#print(np.array([[tp,fp],[fn,tn]]))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83       126\n",
            "           1       0.75      0.80      0.77        89\n",
            "\n",
            "    accuracy                           0.80       215\n",
            "   macro avg       0.80      0.80      0.80       215\n",
            "weighted avg       0.81      0.80      0.81       215\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzHTB5Mv8PA9",
        "outputId": "1ef6ade3-3c7f-4614-d69a-6ecbee2e7767"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "accuracy = accuracy_score( y_test, y_hat)\r\n",
        "print(accuracy) "
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8046511627906977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d3DpKdE8Q38"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T4mzkDS8Qzc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzqQrAvb8Quj"
      },
      "source": [
        "문제53. 예제3. 시본 타이타닉 랜덤포레스트 모델의 oob 점수는 0.74 였고 정확도는 0.80 이었습니다.  \r\n",
        "그래서 예제2번에서 사용한 gridsearch 코드를 가져다가 추가하고 이 모델의 성능을 더 올리시오"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CpW2bIf8XQD"
      },
      "source": [
        "from sklearn import metrics\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# 1단계 csv ---> 데이터 프레임으로 변환\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "df = sns.load_dataset('titanic')\r\n",
        "\r\n",
        "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\r\n",
        "pd.set_option('display.max_columns',15)\r\n",
        "\r\n",
        "# 파생변수를 생성한다.\r\n",
        "mask4 = (df.age<10) | (df.sex=='female') \r\n",
        "df['child_women']=mask4.astype(int)\r\n",
        "\r\n",
        "\r\n",
        "# 2단계 결측치 확인하고 제거하거나 치환한다.\r\n",
        "# 2.1 타이타닉 데이터 프레임의 자료형을 확인한다.\r\n",
        "#df.info()\r\n",
        "\r\n",
        "# 2.2 결측치(NaN) 을 확인한다.\r\n",
        "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\r\n",
        "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함.\r\n",
        "#        embark 와 embark_town 이 같은 데이터여서 embark 컬럼을 삭제해야함\r\n",
        "\r\n",
        "rdf = df.drop(['deck','embark_town'], axis =1)\r\n",
        "\r\n",
        "\r\n",
        "# 2.4 age(나이) 열에 나이가 없는 모든행을 삭제한다.\r\n",
        "# 데이터가 한개라도 없으면 drop 해라 (how = 'any')\r\n",
        "# 모든 데이터가 없으면 drop 해라 (how = 'all')\r\n",
        "\r\n",
        "rdf = rdf.dropna( subset=['age'], how='any', axis=0)\r\n",
        "\r\n",
        "\r\n",
        "# 2.5 embark 열의 NaN 값을 승선도시중 가장 많이 출현한 값으로 치환하기\r\n",
        "\r\n",
        "most_freq = rdf['embarked'].value_counts().idxmax()\r\n",
        "rdf['embarked'].fillna(most_freq, inplace = True)\r\n",
        "\r\n",
        "\r\n",
        "# 3단계 범주형 데이터를 숫자형으로 변환하기\r\n",
        "# 3.1 feature selection (분석에 필요한 속성을 선택)\r\n",
        "\r\n",
        "ndf = rdf[['survived','pclass','sex','age','sibsp','parch','embarked','child_women']]\r\n",
        "\r\n",
        "# 선택된 컬럼중 2개(sex, embarked) 가 범주형이다.\r\n",
        "#3.2 범주형 데이터를 숫자로 변환하기(원핫 인코딩)\r\n",
        "\r\n",
        "gender = pd.get_dummies(ndf['sex'])\r\n",
        "ndf = pd.concat([ndf,gender], axis= 1)\r\n",
        "onehot_embarked = pd.get_dummies(ndf['embarked'])\r\n",
        "ndf = pd.concat([ndf,onehot_embarked],axis=1)\r\n",
        "ndf.drop(['sex','embarked'], axis=1, inplace = True)\r\n",
        "\r\n",
        "\r\n",
        "# 4단계 표준화\r\n",
        "# 4.1 독립변수와 종속변수(라벨) 을 지정한다.\r\n",
        "# survived  pclass   age  sibsp  parch  female  male  C  Q  S\r\n",
        "#   라벨                       데이터\r\n",
        "# 종속변수                     독립변수\r\n",
        "\r\n",
        "x = ndf[ ['pclass', 'age' ,'sibsp', 'parch' ,'female' ,'male', 'C' ,'Q' ,'S', 'child_women'] ]\r\n",
        "y = ndf['survived'] # 종속변수\r\n",
        "\r\n",
        "# 4.2 독립변수들을 표준화 한다.\r\n",
        "from sklearn import preprocessing\r\n",
        "X = preprocessing.StandardScaler().fit(x).transform(x)\r\n",
        "\r\n",
        "\r\n",
        "# 5단계 훈련 데이터를 훈련 데이터 / 테스트 데이터로 나눈다 (7:3)\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,\r\n",
        "                                                 random_state = 33)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_qOENHfBBIp"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIOj8bQB8s68",
        "outputId": "b3ea29d6-5868-4549-f0b8-ec973dc53981"
      },
      "source": [
        "# sklearn 라이브러리 gridsearch, 랜덤포레스트 가져오기\r\n",
        "\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from  sklearn.ensemble   import  RandomForestClassifier \r\n",
        "\r\n",
        "rftree = RandomForestClassifier()  \r\n",
        "\r\n",
        "parameters = {\r\n",
        "    'bootstrap': [True],   # 데이터를 샘플링해서 가져올지 전체를 다 가져올지를 결정\r\n",
        "\t\t\t\t\t# 이상치가 있을때는 bootstrop 설정해야 좋음\r\n",
        "    'max_depth': [80, 90, 100],  # 나무의 깊이\r\n",
        "    'max_features': [2, 3],   # 가장 성능이 좋은 트리의 최종 개수\r\n",
        "    'min_samples_leaf': [3, 4, 5],   # 가지의 리프의 최소 개수\r\n",
        "    'min_samples_split': [8, 10, 12],  # 가지를 split 하는 최소 개수\r\n",
        "    'n_estimators': [100, 200, 300, 1000]  # 나무의 개수\r\n",
        "}\r\n",
        "\r\n",
        "grid_dtree = GridSearchCV(rftree, param_grid=parameters, cv=3, refit=True,  n_jobs = -1, verbose = 2 )\r\n",
        "\r\n",
        "grid_dtree.fit( X_train, y_train )"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   18.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed:  5.4min\n",
            "[Parallel(n_jobs=-1)]: Done 648 out of 648 | elapsed:  5.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False,\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'bootstrap': [True], 'max_depth': [80, 90, 100],\n",
              "                         'max_features': [2, 3], 'min_samples_leaf': [3, 4, 5],\n",
              "                         'min_samples_split': [8, 10, 12],\n",
              "                         'n_estimators': [100, 200, 300, 1000]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1j-ym4J9mUu",
        "outputId": "b3e82591-6127-42bf-9c1c-53cbd7e38c2e"
      },
      "source": [
        "# 7단계 테스트 데이터로 예측을 한다.\r\n",
        "\r\n",
        "y_hat = tree_model.predict( X_test )\r\n",
        "\r\n",
        "\r\n",
        "# 8단계 모형의 예측능력을 평가한다.\r\n",
        "\r\n",
        "from sklearn import metrics\r\n",
        "\r\n",
        "randomforest_matrix = metrics.confusion_matrix( y_test, y_hat )\r\n",
        "\r\n",
        "print( randomforest_matrix )\r\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[102  24]\n",
            " [ 18  71]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BkJ3MgrA2K0"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMswdpww9oFi",
        "outputId": "03570e00-289b-4d59-cc80-53e3d09fa64e"
      },
      "source": [
        "tn, fp, fn, tp = metrics.confusion_matrix( y_test, y_hat ).ravel()\r\n",
        "f1_report = metrics.classification_report( y_test, y_hat )\r\n",
        "print( f1_report )\r\n",
        "#print(np.array([[tp,fp],[fn,tn]]))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83       126\n",
            "           1       0.75      0.80      0.77        89\n",
            "\n",
            "    accuracy                           0.80       215\n",
            "   macro avg       0.80      0.80      0.80       215\n",
            "weighted avg       0.81      0.80      0.81       215\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JgoEQ82A3gd"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JoVaSUU9p6B",
        "outputId": "4095f270-432f-4048-8188-953661d6eb32"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "accuracy = accuracy_score( y_test, y_hat)\r\n",
        "print(accuracy)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8046511627906977\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}